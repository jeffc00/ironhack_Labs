{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the processed titanic dataframe you've created last class\n",
    "\n",
    "Store it in a dataframe called `titanic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_C  Embarked_Q  \\\n",
       "0       3  22.0      1      0   7.2500         1           0           0   \n",
       "1       1  38.0      1      0  71.2833         0           1           0   \n",
       "2       3  26.0      0      0   7.9250         0           0           0   \n",
       "3       1  35.0      1      0  53.1000         0           0           0   \n",
       "4       3  35.0      0      0   8.0500         1           0           0   \n",
       "\n",
       "   Survived  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('titanic_processed.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start simple\n",
    "\n",
    "You will select two variables to create the predictive variables for your problem - store `['Sex','Age']` in a variable called `X`. \n",
    "\n",
    "Also store the variable `'Survived'` into a pandas series called `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Sex_male','Age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[cols]\n",
    "y = titanic.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the `sklearn.model_selection` module, separate your dataset into train and test datasets. \n",
    "\n",
    "In fact, what you are effectively doing is hiding some part of your data to analyse your scores afterwards. As you are handling with a small dataset, separate 20% of your dataset to be your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression for classification\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the LogisticRegression classifier to train your model on your train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the `.predict()` method of your model to generate a prediction for your test dataset. \n",
    "\n",
    "Create a variable called `y_pred` to put the results of the model. Try to understand what exactly the `.predict()` method is doing. \n",
    "\n",
    "_hint: Also try to understand what exactly the method `.predict__proba()` does._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.80       122\n",
      "           1       0.75      0.63      0.69        92\n",
      "\n",
      "    accuracy                           0.75       214\n",
      "   macro avg       0.75      0.74      0.74       214\n",
      "weighted avg       0.75      0.75      0.75       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the results obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the accuracy score of the model. Is accuracy a good measure for this problem? Why? Remember to check how many event occurrences you have on your variable y. Is the dataset balanced in your opinion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "Print the confusion matrix for the results obtained.\n",
    "\n",
    "_hint: You can use the `pd.crosstab()` on your `y__test` variable and your predicted results or use the sklearn.metrics - confusion_matrix method_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pd.crosstab()\n",
    "Store your predicted value and your y_test into a dataframe called pred_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = pd.DataFrame({'y_test': y_test,\n",
    "                             'y_pred': y_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now perform a pd.crosstab on the y_test column and the y_pred column\n",
    "\n",
    "_hint: Store it in a variable called titanic_\\__crosstab_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now use the confusion_matrix method from sklearn.metrics to obtain the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall scores\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html\n",
    "\n",
    "# Calculate the precision and recall scores for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare accuracy, recall and precision for train and test sets. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the number of :\n",
    "1. TRUE POSITIVES\n",
    "2. TRUE NEGATIVES\n",
    "3. FALSE POSITIVES\n",
    "4. FALSE NEGATIVES\n",
    "\n",
    "_hint: Now it's time to use that variable titanic_\\__crosstab you created before_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the TRUE POSITIVE AND FALSE POSITIVE to calculate the precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain with your own words the meaning of the precision score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the TRUE POSITIVE AND FALSE NEGATIVE to calculate the recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain with your own words the meaning of the recall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear Models - Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the following function to test the results for different models. \n",
    "\n",
    "You'll be able to call this function like this, for example:\n",
    "\n",
    "`logistic_regression = score_model(X, y, LogisticRegression())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(X, y, classifier):\n",
    "    import logging\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model = classifier\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    logging.info('Test Results')\n",
    "    logging.info(f'accuracy: {accuracy_score(y_test, y_pred):.2f}')\n",
    "    logging.info(f'recall: {recall_score(y_test, y_pred):.2f}')\n",
    "    logging.info(f'precision: {precision_score(y_test, y_pred):.2f}')\n",
    "    logging.info(f'ROC-AUC: {roc_auc_score(y_test, y_pred):.2f}\\n')\n",
    "    \n",
    "    logging.info('Train Results')\n",
    "    logging.info(f'accuracy: {accuracy_score(y_train, model.predict(x_train)):.2f}')\n",
    "    logging.info(f'recall: {recall_score(y_train, model.predict(x_train)):.2f}')\n",
    "    logging.info(f'precision: {precision_score(y_train, model.predict(x_train)):.2f}')\n",
    "    logging.info(f'ROC-AUC: {roc_auc_score(y_train, model.predict(x_train)):.2f}\\n')\n",
    "    \n",
    "    \n",
    "    logging.info(f'\\n{confusion_matrix(y_test, y_pred)}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this function to create a DecisionTreeClassifier model. Store the model on a variable called `tree`.\n",
    "\n",
    "Make sure you understand what the function `score_model` does. Use the default DecisionTreeClassifier for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting trees\n",
    "\n",
    "Use the the method `plot_tree()` from `sklearn.tree` module to print the tree on your notebook. Play with arguments like `feature_names`, `class_names`, `proportion`, `filled`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think happened? Did you expect such a big tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the `mlxtend.plotting` module, plot the decision boundaries for the Tree classification algorithm.\n",
    "\n",
    "_hint: you have to convert the dataframes to np.array before plotting in this package_\n",
    "\n",
    "Note: Include the labels on the plot using: \n",
    "\n",
    "`plt.xlabel(x_test.columns[0])`\n",
    "\n",
    "`plt.ylabel(x_test.columns[1]);`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(np.array(x_test), np.array(y_test), clf=tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think these wiggles represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do the same for the Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(np.array(x_test), np.array(y_test), clf=logistic_model, )\n",
    "plt.xlabel(x_test.columns[0])\n",
    "plt.ylabel(x_test.columns[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What differences do you observe from them? The variable Age is important for the logistic regression? For different values of Age, how is the decision boundary affected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's fix the tree algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you observed, an overfit occurred when using the default values of the DecisionTreeClassifier. Lesson is: **NEVER USE THOSE**. Let's fix it by using a parameter called `max_depth` for the DecisionTreeClassifier()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with the max_depth parameter to see the changes in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tree = score_model(X, y, DecisionTreeClassifier(max_depth=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the tree again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the decision region again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ...\n",
    "plt.xlabel(x_test.columns[0])\n",
    "plt.ylabel(x_test.columns[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's time to have fun. Let's use more variables. \n",
    "\n",
    "Now have fun plugging in more variables, changing parameters and checking how it affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_list = ['Sex','Age','Fare']\n",
    "X = titanic_df[variables_list]\n",
    "\n",
    "# score_model(X, y, LogisticRegression())\n",
    "# score_model(X, y, DecisionTreeClassifier(max_depth=5))\n",
    "\n",
    "\n",
    "# You may print the tree when using more than 2 variables to understand its results, \n",
    "# but the decision boundary will not be able to be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
